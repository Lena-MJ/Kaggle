{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(curr_dir+\"/train_data/dogs\")\n",
    "os.makedirs(curr_dir+\"/train_data/cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "8d832a76-598c-450b-a05e-44d338b6aca6",
    "_uuid": "2b3dd41dd261ee1ba621f57cb4313f42212a113a"
   },
   "outputs": [],
   "source": [
    "os.makedirs(curr_dir+\"/test_data/dogs\")\n",
    "os.makedirs(curr_dir+\"/test_data/cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "252a0b11-e27d-4e3c-b76b-3ef2810bdf66",
    "_uuid": "a7838afbc091e6f3104e2b197d521f5f464f8720"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"test_data/dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b352a79a-1882-427f-b7a8-1ae9cee3c9b3",
    "_uuid": "6b8ffc4ce183fc48c0ecfe24af930fe3db29b76f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BDCOE-ML\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "6e3103e1-d163-4f49-8679-1b1bd5ce6b3e",
    "_uuid": "b5fa673c7bda35aed3403cc93d5a5657c82b6b52"
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = curr_dir+'//train/'\n",
    "TEST_DIR = curr_dir+'//test/'\n",
    "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\n",
    "train_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "train_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "4c42550c-4c38-4762-948e-28585b4ceb65",
    "_uuid": "72a6490185e751ab95b07a5b609f4ce0535e384d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import shutil\n",
    "for i in train_dogs[:11000]:\n",
    "    a = i.strip().split('/')\n",
    "    shutil.copyfile(i, 'train_data/dogs/'+a[3])\n",
    "for i in train_cats[:11000]:\n",
    "    a = i.strip().split('/')\n",
    "    shutil.copyfile(i, 'train_data/cats/'+a[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "bd603086-7a9d-410d-8f7b-2dce0a0071e0",
    "_uuid": "ab50cda0c91ddb0f880795cbe328031f56504506"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "ec943b53-f802-4853-8e9f-6dccec26dccb",
    "_uuid": "f78a01e5d712eec932738d84ce66a22ec00d4eff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(\"train_data/dogs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "aeb9d61d-f22c-427f-a96e-dbf0928bf71c",
    "_uuid": "710a6227e8f8dc8b8d5f0b384fbcb36bfe3aabd6"
   },
   "outputs": [],
   "source": [
    "for i in train_dogs[11000:12500]:\n",
    "    a = i.strip().split('/')\n",
    "    shutil.copyfile(i, 'test_data/dogs/'+a[3])\n",
    "for i in train_cats[11000:12500]:\n",
    "    a = i.strip().split('/')\n",
    "    shutil.copyfile(i, 'test_data/cats/'+a[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "05322151-8644-4023-a955-83cf64a9e84a",
    "_uuid": "20f78de1612aa902f7c4f9932724553f89f92aa7"
   },
   "outputs": [],
   "source": [
    "os.listdir(\"test_data/dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b26c5bfb-f6b2-4e05-8cfc-935b119baab4",
    "_uuid": "9715e5af79a5f8fcaeb516b96712a668abf9920c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22000 images belonging to 2 classes.\n",
      "Found 3000 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "22000/22000 [==============================] - 3076s 140ms/step - loss: 0.3950 - acc: 0.8178 - val_loss: 0.3658 - val_acc: 0.8473\n",
      "Epoch 2/10\n",
      "22000/22000 [==============================] - 3075s 140ms/step - loss: 0.2793 - acc: 0.8808 - val_loss: 0.3708 - val_acc: 0.8577\n",
      "Epoch 3/10\n",
      "22000/22000 [==============================] - 3071s 140ms/step - loss: 0.2337 - acc: 0.9017 - val_loss: 0.3869 - val_acc: 0.8563\n",
      "Epoch 4/10\n",
      "22000/22000 [==============================] - 3073s 140ms/step - loss: 0.2056 - acc: 0.9140 - val_loss: 0.3878 - val_acc: 0.8619\n",
      "Epoch 5/10\n",
      "22000/22000 [==============================] - 3075s 140ms/step - loss: 0.1865 - acc: 0.9224 - val_loss: 0.3949 - val_acc: 0.8667\n",
      "Epoch 6/10\n",
      "22000/22000 [==============================] - 3073s 140ms/step - loss: 0.1729 - acc: 0.9282 - val_loss: 0.4295 - val_acc: 0.8611\n",
      "Epoch 7/10\n",
      "22000/22000 [==============================] - 3072s 140ms/step - loss: 0.1626 - acc: 0.9332 - val_loss: 0.4621 - val_acc: 0.8613\n",
      "Epoch 8/10\n",
      "22000/22000 [==============================] - 3079s 140ms/step - loss: 0.1539 - acc: 0.9366 - val_loss: 0.4559 - val_acc: 0.8570\n",
      "Epoch 9/10\n",
      "22000/22000 [==============================] - 3132s 142ms/step - loss: 0.1473 - acc: 0.9397 - val_loss: 0.4290 - val_acc: 0.8560\n",
      "Epoch 10/10\n",
      "22000/22000 [==============================] - 3107s 141ms/step - loss: 0.1417 - acc: 0.9421 - val_loss: 0.5797 - val_acc: 0.8566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f7b93d630>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('train_data',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('test_data',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 22000,\n",
    "                         epochs = 10,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "c2a84a2b-8f15-4937-80af-c518f565543f",
    "_uuid": "cd8932d716a61513de90322afc3b0824c3cd6b32"
   },
   "outputs": [],
   "source": [
    "classifier.save(curr_dir+'//my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "fee07d8b-5a3f-45fd-be05-42aa31415431",
    "_uuid": "9c9774dffcf9798e903d68ae6b307ca75f27ec3c"
   },
   "outputs": [],
   "source": [
    "classifier.save_weights(curr_dir+'//my_model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
